{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14980cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, cmudict, opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c329132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"text_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('cmudict')\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLTK objects\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive and negative word lists from the opinion_lexicon\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process text\n",
    "def process_text(text):\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Perform stemming\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join words back to a sentence\n",
    "    processed_text = ' '.join(words)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment scores\n",
    "def calculate_sentiment_scores(processed_text):\n",
    "    positive_score = len([word for word in processed_text.split() if word in positive_words])\n",
    "    negative_score = len([word for word in processed_text.split() if word in negative_words])\n",
    "    \n",
    "    return positive_score, negative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate polarity and subjectivity scores\n",
    "def calculate_polarity_subjectivity(processed_text):\n",
    "    blob = TextBlob(processed_text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    return polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate readability scores\n",
    "def calculate_readability_scores(processed_text):\n",
    "    sentences = sent_tokenize(processed_text)\n",
    "    words = word_tokenize(processed_text)\n",
    "    \n",
    "    average_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    complex_words_count = len([word for word in words if word in positive_words or word in negative_words])\n",
    "    percentage_complex_words = complex_words_count / len(words)\n",
    "    \n",
    "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    return average_sentence_length, percentage_complex_words, fog_index, complex_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad55b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate additional attributes\n",
    "def calculate_additional_attributes(processed_text):\n",
    "    words = word_tokenize(processed_text)\n",
    "    syllable_count = sum([len(list(y for y in x if y[-1].isdigit())) for x in cmudict.words()])\n",
    "    \n",
    "    average_words_per_sentence = len(words) / len(sent_tokenize(processed_text))\n",
    "    word_count = len(words)\n",
    "    average_syllables_per_word = syllable_count / word_count\n",
    "    \n",
    "    personal_pronouns = len([word for word in words if word.lower() in ['i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours']])\n",
    "    \n",
    "    average_word_length = sum(len(word) for word in words) / len(words)\n",
    "    \n",
    "    return average_words_per_sentence, word_count, average_syllables_per_word, personal_pronouns, average_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process URLs\n",
    "def process_url(url):\n",
    "    try:\n",
    "        html = urlopen(url).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        processed_text = process_text(text)\n",
    "        positive_score, negative_score = calculate_sentiment_scores(processed_text)\n",
    "        polarity, subjectivity = calculate_polarity_subjectivity(processed_text)\n",
    "        average_sentence_length, percentage_complex_words, fog_index, complex_words_count = calculate_readability_scores(processed_text)\n",
    "        (average_words_per_sentence, word_count, average_syllables_per_word, personal_pronouns, average_word_length) = calculate_additional_attributes(processed_text)\n",
    "        \n",
    "        return processed_text, positive_score, negative_score, polarity, subjectivity, average_sentence_length, percentage_complex_words, fog_index, complex_words_count,average_words_per_sentence, word_count, average_syllables_per_word, personal_pronouns, average_word_length\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        return None, None, None, None, None, None, None, None, None, None, None, None, None, None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through URLs and extract text and other Attributes\n",
    "scores = df['URL'].apply(process_url)\n",
    "df['Processed_text'] = [score[0] if score is not None else None for score in scores]\n",
    "df['Positive_score'] = [score[1] if score is not None else None for score in scores]\n",
    "df['Negative_score'] = [score[2] if score is not None else None for score in scores]\n",
    "df['polarity'] = [score[3] if score is not None else None for score in scores]\n",
    "df['subjectivity'] = [score[4] if score is not None else None for score in scores]\n",
    "df['average_sentence_length'] = [score[5] if score is not None else None for score in scores]\n",
    "df['percentage_complex_words'] = [score[6] if score is not None else None for score in scores]\n",
    "df['fog_index'] = [score[7] if score is not None else None for score in scores]\n",
    "df['complex_words_count'] = [score[8] if score is not None else None for score in scores]\n",
    "df['average_words_per_sentence'] = [score[9] if score is not None else None for score in scores]\n",
    "df['word_count'] = [score[10] if score is not None else None for score in scores]\n",
    "df['average_syllables_per_word'] = [score[11] if score is not None else None for score in scores]\n",
    "df['personal_pronouns'] = [score[12] if score is not None else None for score in scores]\n",
    "df['average_word_length'] = [score[13] if score is not None else None for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b022e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with processed text\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"text_analysis_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dd49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
